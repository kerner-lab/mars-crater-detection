{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "abe05a91-95f0-422d-8cab-3f0f6de1e3cd",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-04-23 13:01:53.068569: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    }
   ],
   "source": [
    "import numpy as np \n",
    "import os\n",
    "import tensorflow as tf\n",
    "import skimage.io as io\n",
    "import skimage.transform as trans\n",
    "import numpy as np\n",
    "from keras.models import *\n",
    "from keras.layers import *\n",
    "from keras.optimizers import *\n",
    "from keras.callbacks import ModelCheckpoint, LearningRateScheduler\n",
    "from keras import backend as keras\n",
    "from tensorflow.keras.losses import BinaryCrossentropy\n",
    "from keras import layers\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from keras.models import Model, load_model\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "6ad6f43a-64e1-4d27-8b8c-740aa888a5a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras import backend as K\n",
    "def dice_coef(y_true, y_pred, smooth=1):\n",
    "    y_true_f = K.flatten(y_true)\n",
    "    y_pred_f = K.flatten(y_pred)\n",
    "    intersection = K.sum(y_true_f * y_pred_f)\n",
    "    return (2. * intersection + smooth) / (K.sum(y_true_f) + K.sum(y_pred_f) + smooth)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "196beb49-a096-44d4-91ea-0a3a4b589790",
   "metadata": {},
   "outputs": [],
   "source": [
    "def default_unet(): \n",
    "    z1 = Input(shape=(512,512,1))\n",
    "    print('z1: {}'.format(z1.shape))\n",
    "\n",
    "    z2 = Conv2D(16, 3, padding='same', activation='relu')(z1)\n",
    "    p2 = AveragePooling2D(pool_size=2)(z2)\n",
    "    print('z2: {}, \\np2: {}'.format(z2.shape, p2.shape))\n",
    "\n",
    "    z3 = Conv2D(24, 3, padding='same', activation='relu')(p2)\n",
    "    p3 = AveragePooling2D(pool_size=2)(z3)\n",
    "    print('z3: {}, \\np3: {}'.format(z3.shape, p3.shape))\n",
    "\n",
    "    z4 = Conv2D(32, 3, padding='same', activation='relu')(p3)\n",
    "    d4 = Dropout(0.2)(z4)\n",
    "    p4 = AveragePooling2D(pool_size=2)(d4)\n",
    "    print('z4: {}, \\np4: {}'.format(z4.shape, p4.shape))\n",
    "\n",
    "    z5 = Conv2D(48, 3, padding='same', activation='relu')(p4)\n",
    "    d5 = Dropout(0.2)(z5)\n",
    "    p5 = AveragePooling2D(pool_size=2)(d5)\n",
    "    print('z5: {}'.format(z5.shape))\n",
    "\n",
    "    z6 = Conv2D(64, 3, padding='same', activation='relu')(p5)\n",
    "    d6 = Dropout(0.3)(z6)\n",
    "    p6 = AveragePooling2D(pool_size=2)(d6)\n",
    "\n",
    "    z7 = Conv2D(96, 3, padding='same', activation='relu')(p6)\n",
    "    d7 = Dropout(0.4)(z7)\n",
    "    p7 = AveragePooling2D(pool_size=2)(d7)\n",
    "\n",
    "    z8 = Conv2D(128, 3, padding='same', activation='relu')(p7)\n",
    "    d8 = Dropout(0.5)(z8)\n",
    "    p8 = AveragePooling2D(pool_size=2)(d8)\n",
    "\n",
    "    z9 = Conv2D(128, 3, padding='same', activation='relu')(p8)\n",
    "    d9 = Dropout(0.5)(z9)\n",
    "\n",
    "    u9 = UpSampling2D(size=2)(d9)\n",
    "    q9 = Conv2D(128, 3, padding='same', activation='relu')(u9)\n",
    "    d9b = Dropout(0.5)(q9)\n",
    "    a9 = Add()([d9b,z8])\n",
    "\n",
    "    u8 = UpSampling2D(size=2)(a9)\n",
    "    q8 = Conv2D(96, 3, padding='same', activation='relu')(u8)\n",
    "    d8b = Dropout(0.4)(q8)\n",
    "    a8 = Add()([d8b,z7])\n",
    "\n",
    "    u7 = UpSampling2D(size=2)(a8)\n",
    "    q7 = Conv2D(64, 3, padding='same', activation='relu')(u7)\n",
    "    d7b = Dropout(0.3)(q7)\n",
    "    a7 = Add()([d7b,z6])\n",
    "\n",
    "    u6 = UpSampling2D(size=2)(a7)\n",
    "    q6 = Conv2D(48, 3, padding='same', activation='relu')(u6)\n",
    "    d6b = Dropout(0.2)(q6)\n",
    "    a6 = Add()([d6b,z5])\n",
    "\n",
    "    u5 = UpSampling2D(size=2)(a6)\n",
    "    q5 = Conv2D(32, 3, padding='same', activation='relu')(u5)\n",
    "    d5b = Dropout(0.2)(q5)\n",
    "    a5 = Add()([d5b,z4])\n",
    "\n",
    "    u4 = UpSampling2D(size=2)(a5)\n",
    "    q4 = Conv2D(24, 3, padding='same', activation='relu')(u4)\n",
    "    a4 = Add()([q4,z3])\n",
    "\n",
    "    u3 = UpSampling2D(size=2)(a4)\n",
    "    q3 = Conv2D(16, 3, padding='same', activation='relu')(u3)\n",
    "    a3 = Add()([q3,z2])\n",
    "\n",
    "    z_final = Conv2D(1, 3, padding='same', activation='sigmoid')(a3)\n",
    "    #z8 activation = sigmoid or softmax\n",
    "\n",
    "    return Model(inputs = z1, outputs = z_final)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b9e88f9-e105-4428-ad7b-fcc7968279c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.utils import Sequence\n",
    "import numpy as np   \n",
    "import cv2\n",
    "import os\n",
    "from glob import glob\n",
    "\n",
    "class Mygenerator(Sequence):\n",
    "    def __init__(self, x_set, y_set, batch_size):\n",
    "        self.x, self.y = glob(x_set+'/*.png'), glob(y_set+'/*.png')\n",
    "        self.batch_size = batch_size\n",
    "        self.indices = np.arange(np.asarray(self.x).shape[0])\n",
    "\n",
    "    def __len__(self):\n",
    "        return int(np.ceil(len(self.x) / float(self.batch_size)))\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        inds = self.indices[idx * self.batch_size:(idx + 1) * self.batch_size]\n",
    "        batch_x = np.array(self.x)[inds]\n",
    "        batch_y = np.array(self.y)[inds]\n",
    "\n",
    "        # read your data here using the batch lists, batch_x and batch_y\n",
    "        x = []\n",
    "        y = []\n",
    "        for filename in batch_x:\n",
    "            # print(filename)\n",
    "            img = cv2.imread(filename,0)\n",
    "            # if(img.shape[0]<512):\n",
    "            #   img = cv2.copyMakeBorder(img, 128, 128, 128, 128, cv2.BORDER_CONSTANT)\n",
    "            # else:\n",
    "            # img = cv2.resize(img,(512,512))\n",
    "            img = img/255\n",
    "            x.append(img)\n",
    "\n",
    "        for filename in batch_y:\n",
    "            img = cv2.imread(filename,0)\n",
    "            # if(img.shape[0]<512):\n",
    "            #   img = cv2.copyMakeBorder(img, 128, 128, 128, 128, cv2.BORDER_CONSTANT)\n",
    "            # else:\n",
    "            # img = cv2.resize(img,(512,512))\n",
    "            img = np.where(img>0, 1, 0).astype(np.float32)\n",
    "            y.append(img)\n",
    "        \n",
    "        return np.array(x), np.array(y)\n",
    "\n",
    "    def on_epoch_end(self):\n",
    "        np.random.shuffle(self.indices)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9fe2c486-adff-4a30-ad70-24b89e107c23",
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.callbacks import Callback, ModelCheckpoint, ReduceLROnPlateau\n",
    "# tr_img,tr_mask = gen('train')\n",
    "# train = zip(tr_img,tr_mask)\n",
    "# vl_img,vl_mask = gen('val')\n",
    "# val = zip(vl_img,vl_mask)\n",
    "\n",
    "checkpoint = ModelCheckpoint(\n",
    "    'modelunet.h5', \n",
    "    monitor='val_loss', \n",
    "    verbose=0, \n",
    "    save_best_only=True, \n",
    "    save_weights_only=False,\n",
    "    mode='auto'\n",
    "\n",
    ")\n",
    "train = Mygenerator('rectified_data_edges/train/images','rectified_data_edges/train/mask',4)\n",
    "val = Mygenerator('rectified_data_edges/val/images','rectified_data_edges/val/mask',4)\n",
    "reduce_lr = ReduceLROnPlateau(\n",
    "    monitor='val_loss',\n",
    "    patience=4,\n",
    "    verbose=1,\n",
    "    min_lr=1e-6,\n",
    "    min_delta=0.05\n",
    ")\n",
    "model = default_unet()\n",
    "model.compile(optimizer=Adam(lr=1e-3),\n",
    "                  loss='binary_crossentropy',\n",
    "                  metrics=[dice_coef])\n",
    "# model.compile(optimizer = opt, loss = loss, metrics = [dice_coef])\n",
    "\n",
    "STEP_SIZE_TRAIN=3375//16\n",
    "STEP_SIZE_VALID=1800//16\n",
    "\n",
    "# STEP_SIZE_TRAIN=tr_img.n//tr_img.batch_size\n",
    "# STEP_SIZE_VALID=vl_img.n//vl_img.batch_size\n",
    "history = model.fit_generator(train,steps_per_epoch=STEP_SIZE_TRAIN,validation_data=val,validation_steps=STEP_SIZE_VALID,epochs=20, callbacks=[ reduce_lr,checkpoint])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
